{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d36f3909-071c-4f5a-9d5d-968edecf3e68",
   "metadata": {},
   "source": [
    "# LangChain Chains\n",
    "\n",
    "- Agora que aprendemos sobre entradas e saídas de modelos e conexões de dados, podemos finalmente aprender sobre chains.\n",
    "- Chains nos permite vincular a saída de uma chamada LLM à entrada de outra chamada.\n",
    "- Langchain também fornece muitas funcionalidades de chains integradas, como encadear pesquisas de similaridade de documentos com outras chamadas LLM, ações que construímos anteriormente manualmente com Langchain.\n",
    "\n",
    "- https://python.langchain.com/docs/modules/chains/foundational/\n",
    "\n",
    "- Chains tem um bloco de construção básico conhecido como objeto LLMChain.\n",
    "- Você pode pensar no LLMChain apenas como uma simples chamada LLM que terá uma entrada e uma saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea5630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad10ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = AzureChatOpenAI(\n",
    "    openai_api_type=os.getenv('AZOPENAI_API_TYPE'),\n",
    "    openai_api_key=os.getenv('AZOPENAI_API_KEY'),\n",
    "    openai_api_base=os.getenv('AZOPENAI_API_BASE'),\n",
    "    openai_api_version=os.getenv('AZOPENAI_DEPLOYMENT_VERSION'),\n",
    "    deployment_name=os.getenv('AZOPENAI_DEPLOYMENT_NAME'),\n",
    "    model=os.getenv('AZOPENAI_MODEL_NAME'),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdaf641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1539f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = \"Descreva as atribuições do cargo de {nome_cargo}\"\n",
    "human_prompt_template = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_prompt_template])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes\n",
    "prompt = chat_prompt_template.format_messages(nome_cargo='Auditor de Controle Externo')\n",
    "chat_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0664b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depois\n",
    "# Large Language Model Chain\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=chat_llm,  prompt=chat_prompt_template)\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b0a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.run(nome_cargo='Auditor de Controle Externo')\n",
    "result # O retorno é uma String!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b92f94",
   "metadata": {},
   "source": [
    "## Simple Sequential Chain\n",
    "- Agora que entendemos como usar o objeto LLMChain, podemos encadeá-los para criar funcionalidades mais complexas com Langchain.\n",
    "- Lembre-se que um processo de engenharia de prompt pode necessitar de várias etapas, podemos automatizar essas etapas.\n",
    "- *input -> LLMChain -> LLMChain -> LLMChain -> output*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ae12e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "# Um INPUT e um OUTPUT para cada CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9011d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escrita de um documento\n",
    "\n",
    "# Definindo os tópicos/etapas\n",
    "prompt_1 = 'Você é um especialista em auditorias usando a NBASP, descreva as etapas como uma lista numérica para um processo de auditoria de {area_auditoria}. Lembrese de descrever somente as etapas.'\n",
    "# Notem que o HumanPrompt foi criado automaticamente\n",
    "prompt_template_1 = ChatPromptTemplate.from_template(prompt_1)\n",
    "chain_topicos = LLMChain(llm=chat_llm, prompt=prompt_template_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c7a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = 'Você é um especialista em auditorias usando a NBASP, escreva os detalhes das as etapas descritas a seguir: {lista_etapas}'\n",
    "prompt_template_2 = ChatPromptTemplate.from_template(prompt_2)\n",
    "# Poderiamos mudar o modelo\n",
    "chain_detalhes = LLMChain(llm=chat_llm, prompt=prompt_template_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A ordem importa, a segunda variável (lista_etapas) é identificada automaticamente\n",
    "full_chain = SimpleSequentialChain(chains=[chain_topicos, chain_detalhes], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca62b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = full_chain.run('Transferências Volutárias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fca8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d287a40",
   "metadata": {},
   "source": [
    "### Sequential Chain\n",
    "- SequentialChains são muito semelhantes aos SimpleSequentialChains, mas nos permitem ter acesso a todas as saídas dos LLMChains internos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1489ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_topicos = LLMChain(llm=chat_llm, prompt=prompt_template_1, output_key='lista_etapas')\n",
    "chain_detalhes = LLMChain(llm=chat_llm, prompt=prompt_template_2, output_key='texto_final')\n",
    "\n",
    "prompt_3 = 'Escreva uma notícia curta para ser publicada convidando os auditores a ler o texto abaixo: \\n{texto_final}'\n",
    "prompt_template_3 = ChatPromptTemplate.from_template(prompt_3)\n",
    "chain_noticia = LLMChain(llm=chat_llm, prompt=prompt_template_3, output_key='noticia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c9182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_chain = SequentialChain(\n",
    "    chains=[chain_topicos, chain_detalhes, chain_noticia],\n",
    "    input_variables=['area_auditoria'],\n",
    "    output_variables=['lista_etapas', 'texto_final', 'noticia'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = seq_chain(\"Auditoria de Obras\")\n",
    "# Os resultados não serão mostrados, pois vc tem acesso a todas as saídas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04c9dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(resultado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
